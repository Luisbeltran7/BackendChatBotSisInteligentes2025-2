# Proyecto1V2 - FastAPI + RAG (Retrieval-Augmented Generation)

**Chatbot inteligente basado en IA que responde preguntas usando Retrieval-Augmented Generation (RAG) con procesamiento de documentos, embeddings vectoriales y mÃºltiples proveedores de LLM.**

![Python 3.11](https://img.shields.io/badge/python-3.11+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95+-green)
![OpenAI](https://img.shields.io/badge/OpenAI-API-red)
![Groq](https://img.shields.io/badge/Groq-API-orange)

## ğŸ¯ CaracterÃ­sticas Principales

âœ… **Sistema RAG Completo**
- ExtracciÃ³n automÃ¡tica de documentos PDF
- Procesamiento y segmentaciÃ³n de texto (chunking)
- GeneraciÃ³n de embeddings con OpenAI API
- Almacenamiento vectorial con ChromaDB

âœ… **Inteligencia Artificial**
- IntegraciÃ³n con mÃºltiples proveedores LLM (OpenAI, Groq)
- GeneraciÃ³n de respuestas contextuales
- BÃºsqueda semÃ¡ntica de documentos

âœ… **API REST Moderna**
- DocumentaciÃ³n interactiva con Swagger UI
- ValidaciÃ³n automÃ¡tica de datos
- CORS habilitado para integraciones

âœ… **OptimizaciÃ³n de ProducciÃ³n**
- Embeddings precomputados (cacheados)
- Batch processing para eficiencia
- Bajo consumo de recursos en Render

âœ… **EvaluaciÃ³n y Monitoreo**
- Gold Standard para validaciÃ³n
- Logging de consumo de API
- MÃ©tricas de rendimiento

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un sistema completo de pregunta-respuesta que:

1. **Procesa documentos** â†’ Extrae y estructura PDFs
2. **Genera embeddings** â†’ Convierte texto a vectores semÃ¡nticos
3. **Almacena en vector DB** â†’ ChromaDB para bÃºsqueda rÃ¡pida
4. **Responde preguntas** â†’ Busca documentos relevantes + LLM

## ğŸ—‚ï¸ Estructura del Proyecto

```
Proyecto1V2/
â”‚
â”œâ”€â”€ ğŸ“ src/                              # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ main.py                          # FastAPI app
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py                   # Pydantic schemas
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ embedding_service_chroma.py  # Embeddings + ChromaDB
â”‚       â”œâ”€â”€ rag_service.py               # LÃ³gica RAG
â”‚       â”œâ”€â”€ pdf_service.py               # Procesamiento PDFs
â”‚       â””â”€â”€ modelClientFactory.py        # Factory de LLMs
â”‚
â”œâ”€â”€ ğŸ“ scripts/                          # Herramientas auxiliares
â”‚   â”œâ”€â”€ preparar_corpus.py               # Procesa PDFs
â”‚   â””â”€â”€ datasets/                        # PDFs
â”‚
â”œâ”€â”€ ğŸ“ metricas y evaluacion/           # EvaluaciÃ³n
â”‚   â”œâ”€â”€ preguntasGold.py                 # Script de test
â”‚   â””â”€â”€ PreguntasGold.csv                # Preguntas de oro
â”‚
â”œâ”€â”€ ğŸ“ chroma_persist/                   # ChromaDB persistente
â”‚   â””â”€â”€ embeddings_precomputed.pkl       # Embeddings cacheados
â”‚
â”œâ”€â”€ ğŸ“ logs/                             # Logs del sistema
â”œâ”€â”€ ğŸ“ tests/                            # Tests unitarios
â”œâ”€â”€ ğŸ“ env/                              # Entorno virtual
â”‚
â”œâ”€â”€ Dockerfile                           # Imagen Docker
â”œâ”€â”€ docker-compose.yml                   # Servicios
â”œâ”€â”€ requirements.txt                     # Dependencias
â”œâ”€â”€ .env                                 # Variables de entorno
â”œâ”€â”€ .gitignore                           # Git ignores
â””â”€â”€ README.md                            # Este archivo
```

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Docker (Recomendado)

```bash
# Clonar repositorio
git clone https://github.com/Luisbeltran7/BackendChatBotSisInteligentes2025-2.git
cd Proyecto1V2

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus claves API

# Ejecutar con Docker
docker compose up --build
```

La API estarÃ¡ en: `http://localhost:8000`

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Crear entorno virtual
python -m venv env
.\env\Scripts\Activate.ps1  # Windows
source env/bin/activate     # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables
cp .env.example .env
# Editar .env

# Ejecutar
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno (.env)

```env
# API Keys
OPENAI_API_KEY=sk-proj-xxx...
GROQ_API_KEY=gsk_xxx...

# Servidor
HOST=0.0.0.0
PORT=8000
ENV=development
DEBUG=true

# Embeddings
EMBEDDER_ENABLED=true
USE_OPENAI_EMBEDDINGS=true

# Logs
LOG_LEVEL=INFO
```

| Variable | DescripciÃ³n | Requerido |
|----------|-------------|----------|
| `OPENAI_API_KEY` | Clave API OpenAI | SÃ­ |
| `GROQ_API_KEY` | Clave API Groq | No |
| `HOST` | Host del servidor | No (default: 0.0.0.0) |
| `PORT` | Puerto del servidor | No (default: 8000) |
| `ENV` | Entorno (development/production) | No |
| `EMBEDDER_ENABLED` | Cargar sentence-transformers | No |
| `USE_OPENAI_EMBEDDINGS` | Usar OpenAI embeddings | No (default: true) |

## ğŸ“¡ API Endpoints

### Health Check
```http
GET /health
```
Respuesta:
```json
{"status": "ok"}
```

### Hacer una Pregunta
```http
POST /question
Content-Type: application/json

{
  "question": "Â¿QuÃ© es la inteligencia artificial?",
  "model_provider": "openai",
  "mode": "detallada",
  "top_k": 3
}
```

Respuesta:
```json
{
  "question": "Â¿QuÃ© es la inteligencia artificial?",
  "answer": "La inteligencia artificial es...",
  "sources": [
    {
      "document": "archivo.pdf",
      "page": 5,
      "relevance": 0.95
    }
  ],
  "confidence": 0.88
}
```

### DocumentaciÃ³n Interactiva
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ”§ Scripts y Herramientas

### 1. Procesamiento de PDFs
```bash
python scripts/preparar_corpus.py
```
- Extrae texto de PDFs
- Detecta tÃ­tulos y negrillas
- Estructura contenido en Markdown
- Genera PDFs ordenados

### 2. EvaluaciÃ³n con Gold Standard
```bash
python "metricas y evaluacion/preguntasGold.py"
```
- Lee preguntas de referencia
- Genera respuestas usando la API
- Compara con Gold Standard
- Genera reportes en CSV

### 3. AnÃ¡lisis de Respuestas
```bash
python scripts/contadorNo.py
```

## ğŸ“Š Ejemplos de Uso

### Con cURL
```bash
curl -X POST http://localhost:8000/question \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Â¿QuÃ© es la inteligencia artificial?",
    "model_provider": "openai",
    "mode": "detallada",
    "top_k": 3
  }'
```

### Con Python
```python
import requests

url = "http://localhost:8000/question"
payload = {
    "question": "Â¿CuÃ¡l es el impacto de la IA en la educaciÃ³n?",
    "model_provider": "openai",
    "mode": "detallada",
    "top_k": 3
}

response = requests.post(url, json=payload)
result = response.json()

print(f"Pregunta: {result['question']}")
print(f"Respuesta: {result['answer']}")
print(f"Confianza: {result['confidence']}")
```

### Con JavaScript
```javascript
const response = await fetch('http://localhost:8000/question', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    question: "Â¿QuÃ© es machine learning?",
    model_provider: "openai",
    mode: "detallada",
    top_k: 3
  })
});

const data = await response.json();
console.log(data.answer);
```

## ğŸ§ª Testing

### Ejecutar Tests
```bash
pytest tests/ -v
```

### Cobertura
```bash
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ˆ Monitoreo y Logs

- **Logs de aplicaciÃ³n**: `logs/app.log`
- **Logs de consumo**: `logs/consumo_logs.csv`
- **Ver logs en tiempo real**:
```bash
docker compose logs -f
```

## ğŸš€ Despliegue en Render

### Pasos

1. **Preparar repositorio**:
   ```bash
   git add .
   git commit -m "Deploy to Render"
   git push
   ```

2. **En Render.com**:
   - Crear nuevo Web Service
   - Conectar repositorio GitHub
   - Build: `pip install -r requirements.txt`
   - Start: `uvicorn src.main:app --host 0.0.0.0 --port $PORT`

3. **Configurar variables de entorno**:
   - `OPENAI_API_KEY`: Tu clave OpenAI
   - `ENV`: production
   - `EMBEDDER_ENABLED`: false
   - `USE_OPENAI_EMBEDDINGS`: true

### OptimizaciÃ³n para Render

Para ahorrar recursos en la versiÃ³n gratuita:
- âœ… Usa OpenAI embeddings (0 MB local)
- âœ… Embeddings precomputados cacheados
- âœ… `ENV=production` (desactiva extras)
- âœ… Batch processing eficiente

## ğŸ”’ Seguridad

- Las claves API se cargan desde `.env` (nunca en cÃ³digo)
- `.env` estÃ¡ en `.gitignore`
- CORS habilitado solo para dominios configurados
- Rate limiting recomendado en producciÃ³n

## ğŸ› SoluciÃ³n de Problemas

### Error: "No module named 'openai'"
```bash
pip install openai
```

### Error: "OPENAI_API_KEY not configured"
```bash
# Verifica que .env existe y contiene:
OPENAI_API_KEY=sk-proj-xxx...
```

### Puerto 8000 en uso
```bash
# Windows
netstat -ano | findstr :8000

# Linux/Mac
lsof -i :8000
```

### ChromaDB con errores
```bash
# Limpiar base de datos
Remove-Item -Path "chroma_persist" -Recurse -Force
# Reiniciar servidor
```

## ğŸ“š Recursos Adicionales

- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [OpenAI API](https://platform.openai.com/)
- [Groq API](https://console.groq.com/)
- [ChromaDB](https://www.trychroma.com/)
- [RAG Overview](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature: `git checkout -b feature/amazing-feature`
3. Commit cambios: `git commit -m 'Add amazing feature'`
4. Push a rama: `git push origin feature/amazing-feature`
5. Abrir Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ‘¤ Autor

**Luis BeltrÃ¡n**
- GitHub: [@Luisbeltran7](https://github.com/Luisbeltran7)
- Repositorio: [BackendChatBotSisInteligentes2025-2](https://github.com/Luisbeltran7/BackendChatBotSisInteligentes2025-2)

## ğŸ“§ Soporte

Para preguntas o reportar issues, por favor:
- Abrir un issue en GitHub
- Enviar email: [tu-email]

---

**Ãšltima actualizaciÃ³n**: Diciembre 2025  
**VersiÃ³n**: 2.0.0  
**Estado**: âœ… ProducciÃ³n Ready

response = requests.post(url, json=payload)
print(response.json())
```

## Testing

### Ejecutar Tests

```powershell
pytest tests/ -v
```

### Cobertura de Tests

```powershell
pytest tests/ --cov=src --cov-report=html
```

## Logging y Monitoreo

Los logs se guardan en `logs/` con la siguiente estructura:
- `consumo_logs.csv` - Registro de consumo de API
- `app.log` - Logs generales de la aplicaciÃ³n

Para ver logs en tiempo real con Docker:
```powershell
docker compose logs -f
```

## Troubleshooting

### Docker

Si Docker no arranca:
```powershell
# Verificar estado del servicio
Get-Service -Name com.docker.service

# Iniciar el servicio si estÃ¡ detenido
Start-Service -Name com.docker.service
```

### Puertos

Si el puerto 8000 estÃ¡ en uso:
```powershell
# Verificar quÃ© proceso usa el puerto
Get-NetTCPConnection -LocalPort 8000 -ErrorAction SilentlyContinue | Select-Object OwningProcess

# Cambiar puerto en docker-compose.yml
# ports:
#   - "8080:8000"
```

### API Keys

Si obtienes errores de autenticaciÃ³n:
1. Verifica que `.env` existe y tiene las claves correctas
2. Reinicia el contenedor: `docker compose restart`
3. Comprueba que las claves no tienen espacios en blanco

### Encoding de Archivos

Si hay problemas con caracteres especiales:
- AsegÃºrate de que los CSV se abren con encoding `utf-8`
- Los PDFs se procesan automÃ¡ticamente con limpieza de caracteres

## Performance y OptimizaciÃ³n

- **Embeddings**: Se cachean automÃ¡ticamente en `vector_store/`
- **BÃºsqueda**: Usa FAISS para bÃºsqueda vectorial rÃ¡pida
- **Timeouts**: Configurados a 60 segundos para llamadas a API

## ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature: `git checkout -b feature/AmazingFeature`
3. Commit cambios: `git commit -m 'Add AmazingFeature'`
4. Push a rama: `git push origin feature/AmazingFeature`
5. Abrir Pull Request

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## Contacto y Soporte

Para preguntas o reportar bugs, por favor crear un issue en el repositorio.